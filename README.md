# Text-guided infrared and visible image fusion

This is the official implementation of our paper "".

When we train on LLVIP dataset, the text for visible images is "low light degradation" and the text for infrared images is "low contrast and blurred"; when we predict on LLVIP and MSRS dataset, the text for visible images is "maybe low light degradation and overexposure degradation in visible images." and the text for infrared images is "low contrast issues"  ratio 0.6 0.2 0.2
